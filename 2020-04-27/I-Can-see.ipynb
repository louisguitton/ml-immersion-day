{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import boto3\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import requests\n",
    "import time\n",
    "import pprint  #print json \n",
    "\n",
    "\n",
    "rekognition = boto3.client('rekognition')\n",
    "polly = boto3.client('polly')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API calls to Rekognition \n",
    "def identify_image(url):\n",
    "    with requests.get(url) as response:\n",
    "        image = response.content\n",
    "        print('\\n\\n\\nDetecting labels...')\n",
    "        response = rekognition.detect_labels(Image={'Bytes': image}, MaxLabels=3, MinConfidence=65)\n",
    "        labels = response['Labels']\n",
    "        #print(str(labels))\n",
    "        pprint.pprint(response)\n",
    "        print('\\n\\n\\n\\nDetecting faces...')\n",
    "        response = rekognition.detect_faces(Attributes=[ 'ALL' ], Image={'Bytes':image})\n",
    "        face_details_list = response['FaceDetails']\n",
    "        #print(str(face_details_list))\n",
    "        pprint.pprint(response)\n",
    "        print('\\n\\n\\n\\nDetecting text...')\n",
    "        response = rekognition.detect_text(Image={'Bytes':image})\n",
    "        text_detection = response['TextDetections']\n",
    "        #print(str(text_detection))\n",
    "        pprint.pprint(response)\n",
    "\n",
    "\n",
    "    return labels, face_details_list, text_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API calls to polly \n",
    "def speak(polly, text, format='mp3', voice='Joanna'):\n",
    "    \n",
    "    import IPython\n",
    "    resp = polly.synthesize_speech(OutputFormat=format, Text=text, VoiceId=voice)\n",
    "    sound_file = open('polly_description.mp3', 'wb')\n",
    "    sound_bytes = resp['AudioStream'].read()\n",
    "    sound_file.write(sound_bytes)\n",
    "    sound_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliar code to build a sentece from a json that recognition return \n",
    "\n",
    "def join_with_and(words):\n",
    "    if len(words) == 0:\n",
    "        return ''\n",
    "    if len(words) == 1:\n",
    "        return words[0]\n",
    "    else:\n",
    "        last_word = words.pop()\n",
    "        return ', '.join(words) + ' and ' + last_word\n",
    "\n",
    "def identify_image(url):\n",
    "    with requests.get(url) as response:\n",
    "        image = response.content\n",
    "        print('\\n\\n\\nDetecting labels...')\n",
    "        response = rekognition.detect_labels(Image={'Bytes': image}, MaxLabels=3, MinConfidence=65)\n",
    "        labels = response['Labels']\n",
    "        print(str(labels))\n",
    "        print('\\n\\n\\n\\nDetecting faces...')\n",
    "        response = rekognition.detect_faces(Attributes=[ 'ALL' ], Image={'Bytes':image})\n",
    "        face_details_list = response['FaceDetails']\n",
    "        print(str(face_details_list))\n",
    "        print('\\n\\n\\n\\nDetecting text...')\n",
    "        response = rekognition.detect_text(Image={'Bytes':image})\n",
    "        text_detection = response['TextDetections']\n",
    "        print(str(text_detection))\n",
    "\n",
    "    return labels, face_details_list, text_detection\n",
    "\n",
    "\n",
    "def find_article(words,corpus_bigrams_counter, corpus_trigrams_counter):\n",
    "\n",
    "    articles = ['a', 'an', 'some']\n",
    "    max = 0\n",
    "    best_article = ''\n",
    "    print(words)\n",
    "    for article in articles:\n",
    "        if len(words) == 1:\n",
    "            found = corpus_bigrams_counter[(article, words[0])]\n",
    "        elif len(words) == 2:\n",
    "            found = corpus_trigrams_counter[(article, words[0], words[1])]\n",
    "        else:\n",
    "            found = 0\n",
    "        print(article + ' ' + str(found))\n",
    "        if found > max:\n",
    "            print(\"max!\")\n",
    "            max = found\n",
    "            best_article = article + ' '\n",
    "    return best_article\n",
    "\n",
    "def init_ngrams():\n",
    "    corpus = nltk.corpus.brown\n",
    "    try:\n",
    "        print(len(corpus.words()))\n",
    "    except:\n",
    "        print('Downloading corpus')\n",
    "        nltk.download('brown')\n",
    "\n",
    "    print('Computing bigrams...')\n",
    "    corpus_bigrams = nltk.ngrams(corpus.words(), 2)\n",
    "    corpus_trigrams = nltk.ngrams(corpus.words(), 3)\n",
    "\n",
    "    print('Computing counter...')\n",
    "    corpus_bigrams_counter = Counter(corpus_bigrams)\n",
    "    corpus_trigrams_counter = Counter(corpus_trigrams)\n",
    "    return corpus_bigrams_counter, corpus_trigrams_counter\n",
    "\n",
    "\n",
    "corpus_bigrams_counter, corpus_trigrams_counter = init_ngrams()\n",
    "    \n",
    "def format_text(labels,face_details_list,text_detection):\n",
    "\n",
    "    sentence = 'I see '\n",
    "    if len(labels) + len(face_details_list) == 0:\n",
    "        sentence += 'nothing'\n",
    "\n",
    "    first = True\n",
    "    for label in labels:\n",
    "        if first:\n",
    "            first = False\n",
    "        else:\n",
    "            sentence += ', '\n",
    "        name = label['Name'].lower()\n",
    "        article = find_article(name.split(' '),corpus_bigrams_counter, corpus_trigrams_counter)\n",
    "        sentence += article + name ###.replace('_', ' ')\n",
    "\n",
    "    if len(labels) > 0 and len(face_details_list) > 0:\n",
    "        sentence += ', '\n",
    "\n",
    "    first = True\n",
    "    for faceDetail in face_details_list:\n",
    "        if first:\n",
    "            first = False\n",
    "        else:\n",
    "            sentence += ', '\n",
    "        details = []\n",
    "        gender = faceDetail['Gender']['Value'].lower()\n",
    "        details.append('a ' + gender + ' face')\n",
    "        ageRange = str(faceDetail['AgeRange']['Low']) + '-' + str(faceDetail['AgeRange']['High'])\n",
    "        details.append('aged ' + ageRange)\n",
    "        if gender == 'male':\n",
    "            who = 'he'\n",
    "            whose = 'his'\n",
    "        elif gender == 'female':\n",
    "            who = 'she'\n",
    "            whose = 'her'\n",
    "        else:\n",
    "            who = 'it'\n",
    "            whose = 'its'\n",
    "\n",
    "        if faceDetail['Mustache']['Value']:\n",
    "            details.append('with mustache')\n",
    "        if faceDetail['Beard']['Value']:\n",
    "            details.append('with a beard')\n",
    "        if faceDetail['Sunglasses']['Value']:\n",
    "            details.append('wearing sunglasses')\n",
    "        elif faceDetail['Eyeglasses']['Value']:\n",
    "            details.append('wearing eyeglasses')\n",
    "        if faceDetail['EyesOpen']['Value']:\n",
    "            details.append(whose + ' eyes are open')\n",
    "        if not faceDetail['EyesOpen']['Value']:\n",
    "            details.append(whose + ' eyes are closed')\n",
    "        if faceDetail['MouthOpen']['Value']:\n",
    "            details.append(whose + ' mouth is open')\n",
    "        if not faceDetail['MouthOpen']['Value']:\n",
    "            details.append(whose + ' mouth is closed')\n",
    "        if faceDetail['Smile']['Value']:\n",
    "            details.append(who + ' is smiling')\n",
    "        emotions = []\n",
    "        for emotion in faceDetail['Emotions']:\n",
    "            if emotion['Confidence'] > 80:\n",
    "                emotions.append('very ' + emotion['Type'].lower())\n",
    "            elif emotion['Confidence'] > 80:\n",
    "                emotions.append(emotion['Type'].lower())\n",
    "            elif emotion['Confidence'] > 80:\n",
    "                emotions.append('a little ' + emotion['Type'].lower())\n",
    "        if len(emotions) > 0:\n",
    "            details.append(who + ' looks ' + join_with_and(emotions))\n",
    "        sentence += join_with_and(details)\n",
    "\n",
    "    sentence += '. '\n",
    "\n",
    "    if (text_detection):\n",
    "        sentence += 'I can also read: '\n",
    "        for text_like in text_detection:\n",
    "            if text_like['Type'] == 'LINE':\n",
    "                sentence += ', ' + text_like['DetectedText']\n",
    "    print(sentence)\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please try with different images\n",
    "# DON'T FORGET TO PLAY AUDIO!!!! \n",
    "    \n",
    "image_url = \"https://i.pinimg.com/originals/b7/cc/68/b7cc68a555e48b90004735c21c107b8e.jpg\"\n",
    "labels, face_details_list, text_detection = identify_image(image_url.strip())\n",
    "\n",
    "sentence = format_text(labels,face_details_list,text_detection)\n",
    "speak(polly, sentence)\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML('<iframe src=\\'polly_description.mp3\\' width=600 height=250></iframe> <iframe src='+image_url+' width=900 height=500></iframe> ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
